{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eba2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in /home/andy/andyVenv/lib/python3.12/site-packages (from keras) (2.3.3)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: packaging in /home/andy/andyVenv/lib/python3.12/site-packages (from keras) (25.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andy/andyVenv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/andy/andyVenv/lib/python3.12/site-packages (from tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andy/andyVenv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/andy/andyVenv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/andy/andyVenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andy/andyVenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/andy/andyVenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andy/andyVenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/andy/andyVenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/andy/andyVenv/lib/python3.12/site-packages (from rich->keras) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/andy/andyVenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m408.8/408.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357534cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pyarrow\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e89e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/andy/6309GP\n",
      "Loading: sequence_hdfs_20251024_183457.bin\n",
      "Index(['SessionId', 'EventSequence', 'Label'], dtype='object')\n",
      "(575061, 3)\n",
      "                  SessionId  \\\n",
      "0  blk_-1608999687919862906   \n",
      "1   blk_7503483334202473044   \n",
      "2  blk_-3544583377289625738   \n",
      "3  blk_-9073992586687739851   \n",
      "4   blk_7854771516489510256   \n",
      "\n",
      "                                       EventSequence  Label  \n",
      "0  E5 E22 E5 E5 E11 E11 E9 E9 E11 E9 E26 E26 E26 ...      0  \n",
      "1  E5 E5 E22 E5 E11 E9 E11 E9 E11 E9 E26 E26 E26 ...      0  \n",
      "2  E5 E22 E5 E5 E11 E9 E11 E9 E11 E9 E3 E26 E26 E...      1  \n",
      "3  E5 E22 E5 E5 E11 E9 E11 E9 E11 E9 E26 E26 E26 ...      0  \n",
      "4  E5 E5 E22 E5 E11 E9 E11 E9 E11 E9 E26 E26 E26 ...      0  \n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"./\")\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "# Find all matching files\n",
    "files = sorted(glob.glob(\"sequence_hdfs_*.bin\"), key=os.path.getmtime)\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No sequence_hdfs_*.bin files found!\")\n",
    "# Pick the most recent one\n",
    "latest_file = files[-1]\n",
    "print(f\"Loading: {latest_file}\")\n",
    "# Load as Feather\n",
    "df_sequence = pd.read_feather(latest_file)\n",
    "print(df_sequence.columns)\n",
    "print(df_sequence.shape)\n",
    "print(df_sequence.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f0a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402542, 3) (172519, 3)\n",
      "Label\n",
      "0    0.970719\n",
      "1    0.029281\n",
      "Name: proportion, dtype: float64\n",
      "Label\n",
      "0    0.970722\n",
      "1    0.029278\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_sequence_dataset(df, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Split a sequence dataset into training and evaluation sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns ['SessionId', 'EventSequence', 'Label'].\n",
    "    test_size : float\n",
    "        Fraction of the dataset to reserve for evaluation (default 0.3).\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sequence_train : pd.DataFrame\n",
    "    sequence_eval : pd.DataFrame\n",
    "    \"\"\"\n",
    "    sequence_train, sequence_eval = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df[\"Label\"],  # preserve label distribution\n",
    "        shuffle=True\n",
    "    )\n",
    "    return sequence_train.reset_index(drop=True), sequence_eval.reset_index(drop=True)\n",
    "\n",
    "sequence_train, sequence_eval = split_sequence_dataset(df_sequence)\n",
    "print(sequence_train.shape, sequence_eval.shape)\n",
    "print(sequence_train[\"Label\"].value_counts(normalize=True))\n",
    "print(sequence_eval[\"Label\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dd9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390755, 3)\n",
      "Label\n",
      "0    390755\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_normal_subset(df_train, label_col=\"Label\"):\n",
    "    return df_train[df_train[label_col] == 0].reset_index(drop=True)\n",
    "\n",
    "sequence_train_normal = get_normal_subset(sequence_train)\n",
    "print(sequence_train_normal.shape)\n",
    "print(sequence_train_normal[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cbd729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/andyVenv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train normal: (390755, 29) Eval: (172519, 29)\n",
      "Labels (train normal): [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Identity tokenizer function\n",
    "def identity_tokenizer(s: str):\n",
    "    # For pre-tokenized input (space-separated)\n",
    "    return s.split()\n",
    "\n",
    "# Vectorizer setup\n",
    "tfidf_id = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False, preprocessor=None)\n",
    "tfidf_matrix_id = tfidf_id.fit_transform(df_sequence[\"EventSequence\"].astype(str))\n",
    "\n",
    "# Get feature names\n",
    "feature_names_id = np.array(tfidf_id.get_feature_names_out())\n",
    "\n",
    "# Prepare X and y\n",
    "X = tfidf_matrix_id\n",
    "y = df_sequence[\"Label\"].values\n",
    "\n",
    "# Split into train and eval sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Filter for normal class (0) only in training set\n",
    "mask_normal = (y_train == 0)\n",
    "X_train_normal = X_train[mask_normal]\n",
    "y_train_normal = y_train[mask_normal]  # Make sure to filter y_train as well\n",
    "\n",
    "print(\"Train normal:\", X_train_normal.shape, \"Eval:\", X_eval.shape)\n",
    "print(\"Labels (train normal):\", np.unique(y_train_normal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2e358",
   "metadata": {},
   "source": [
    "threat to validity: the use of autoencoder expects a matrix with the same size. This is a poor combination when applied with MCV and TF-IDF: \n",
    "\n",
    "IF there are novel templates in eval set in comparison to training set, the autoencoder breaks. \n",
    "\n",
    "In post, it would be better to use an embedding such as word to vect where the matrix is of a fixed dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b613d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_mlp_results(result_df):\n",
    "    \"\"\"\n",
    "    Compute classification metrics from MLP results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_df : pd.DataFrame\n",
    "        Must contain columns: ['true_label', 'pred_label']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        Dictionary of precision, recall, f1, and auc scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = result_df[\"true_label\"].astype(int)\n",
    "    y_pred = result_df[\"pred_label\"].astype(int)\n",
    "\n",
    "    # Compute classification metrics\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # ROC AUC can be computed if the labels are binary (0 or 1)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = None  # If AUC can't be computed, set it to None\n",
    "\n",
    "    # Prepare metrics dictionary\n",
    "    metrics = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "    print(\"\\nðŸ“Š Evaluation metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        if v is not None:\n",
    "            print(f\"{k:10s}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"{k:10s}: Not available (AUC could not be computed)\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a9996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_mlp(X_train, X_eval, y_train, y_eval, hidden_layer_sizes=(128, 64), epochs=30, batch_size=32, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Train an MLPClassifier and evaluate its performance on an evaluation set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array-like\n",
    "        Training data.\n",
    "    X_eval : array-like\n",
    "        Evaluation data.\n",
    "    y_train : array-like\n",
    "        Labels for training data.\n",
    "    y_eval : array-like\n",
    "        Labels for evaluation data.\n",
    "    hidden_layer_sizes : tuple\n",
    "        Sizes of the hidden layers.\n",
    "    epochs : int\n",
    "        Number of epochs for training.\n",
    "    batch_size : int\n",
    "        Batch size for training.\n",
    "    lr : float\n",
    "        Learning rate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame\n",
    "        DataFrame with columns ['true_label', 'pred_label', 'reconstruction_error'].\n",
    "    model : MLPClassifier\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(f\"Training MLP on {X_train.shape[0]} samples, evaluating on {X_eval.shape[0]} samples...\")\n",
    "\n",
    "    # Initialize the MLPClassifier\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                          max_iter=epochs,\n",
    "                          learning_rate_init=lr,\n",
    "                          batch_size=batch_size,\n",
    "                          verbose=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the evaluation set\n",
    "    y_pred = model.predict(X_eval)\n",
    "\n",
    "    # Build output DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"true_label\": y_eval,\n",
    "        \"pred_label\": y_pred\n",
    "    })\n",
    "\n",
    "    print(\"\\nâœ… Training complete.\")\n",
    "    print(result_df[\"pred_label\"].value_counts())\n",
    "\n",
    "    return result_df, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94c8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_classification_results_by_label(result_df):\n",
    "    \"\"\"\n",
    "    Compute summary statistics (mean, std, count) of predictions by label \n",
    "    for normal (label=0) and anomaly (label=1) samples.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_df : pd.DataFrame\n",
    "        DataFrame with at least columns ['true_label', 'pred_label'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_df : pd.DataFrame\n",
    "        Summary of prediction count, true positive, false positive, etc. by label.\n",
    "    \"\"\"\n",
    "\n",
    "    if not {\"true_label\", \"pred_label\"}.issubset(result_df.columns):\n",
    "        raise ValueError(\"result_df must contain 'true_label' and 'pred_label' columns\")\n",
    "\n",
    "    # Create a confusion matrix\n",
    "    confusion_matrix = pd.crosstab(result_df[\"true_label\"], result_df[\"pred_label\"], \n",
    "                                   rownames=[\"True Label\"], colnames=[\"Predicted Label\"])\n",
    "\n",
    "    # Calculate summary statistics for each label (Normal and Anomaly)\n",
    "    summary = (\n",
    "        result_df.groupby(\"true_label\")[\"pred_label\"]\n",
    "        .agg([\"count\", \"mean\", \"std\"])\n",
    "        .rename(index={0: \"Normal (0)\", 1: \"Anomaly (1)\"})\n",
    "    )\n",
    "\n",
    "    print(\"\\nðŸ“Š Classification Result Summary by Label:\")\n",
    "    print(summary)\n",
    "\n",
    "    # Additional interpretation based on counts and prediction distribution\n",
    "    normal_pred_count = summary.loc[\"Normal (0)\", \"count\"]\n",
    "    anomaly_pred_count = summary.loc[\"Anomaly (1)\", \"count\"]\n",
    "\n",
    "    print(f\"\\nNormal predictions count: {normal_pred_count}\")\n",
    "    print(f\"Anomaly predictions count: {anomaly_pred_count}\")\n",
    "\n",
    "    # Confusion matrix interpretation\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    # Add insights on model's performance for Normal vs. Anomaly detection\n",
    "    true_positives = confusion_matrix.loc[1, 1] if 1 in confusion_matrix.index and 1 in confusion_matrix.columns else 0\n",
    "    false_positives = confusion_matrix.loc[0, 1] if 0 in confusion_matrix.index and 1 in confusion_matrix.columns else 0\n",
    "    false_negatives = confusion_matrix.loc[1, 0] if 1 in confusion_matrix.index and 0 in confusion_matrix.columns else 0\n",
    "    true_negatives = confusion_matrix.loc[0, 0] if 0 in confusion_matrix.index and 0 in confusion_matrix.columns else 0\n",
    "\n",
    "    # Calculate precision, recall, and F1 for both classes\n",
    "    precision_normal = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0\n",
    "    recall_normal = true_negatives / (true_negatives + false_negatives) if (true_negatives + false_negatives) > 0 else 0\n",
    "    precision_anomaly = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    recall_anomaly = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "\n",
    "    print(f\"\\nPrecision (Normal): {precision_normal:.4f}\")\n",
    "    print(f\"Recall (Normal): {recall_normal:.4f}\")\n",
    "    print(f\"Precision (Anomaly): {precision_anomaly:.4f}\")\n",
    "    print(f\"Recall (Anomaly): {recall_anomaly:.4f}\")\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b20959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP on 402542 samples, evaluating on 172519 samples...\n",
      "Iteration 1, loss = 0.00473507\n",
      "Iteration 2, loss = 0.00191899\n",
      "Iteration 3, loss = 0.00168320\n",
      "Iteration 4, loss = 0.00158739\n",
      "Iteration 5, loss = 0.00151933\n",
      "Iteration 6, loss = 0.00144901\n",
      "Iteration 7, loss = 0.00142690\n",
      "Iteration 8, loss = 0.00140413\n",
      "Iteration 9, loss = 0.00136318\n",
      "Iteration 10, loss = 0.00131422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/andyVenv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training complete.\n",
      "pred_label\n",
      "0    167466\n",
      "1      5053\n",
      "Name: count, dtype: int64\n",
      "   true_label  pred_label\n",
      "0           0           0\n",
      "1           0           0\n",
      "2           0           0\n",
      "3           0           0\n",
      "4           0           0\n",
      "5           0           0\n",
      "6           0           0\n",
      "7           0           0\n",
      "8           0           0\n",
      "9           0           0\n",
      "\n",
      "ðŸ“Š Evaluation metrics:\n",
      "precision : 0.9954\n",
      "recall    : 0.9958\n",
      "f1_score  : 0.9956\n",
      "accuracy  : 0.9997\n",
      "auc       : 0.9979\n",
      "\n",
      "ðŸ“Š Classification Result Summary by Label:\n",
      "              count      mean       std\n",
      "true_label                             \n",
      "Normal (0)   167468  0.000137  0.011718\n",
      "Anomaly (1)    5051  0.995842  0.064352\n",
      "\n",
      "Normal predictions count: 167468\n",
      "Anomaly predictions count: 5051\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted Label       0     1\n",
      "True Label                   \n",
      "0                167445    23\n",
      "1                    21  5030\n",
      "\n",
      "Precision (Normal): 0.9999\n",
      "Recall (Normal): 0.9999\n",
      "Precision (Anomaly): 0.9958\n",
      "Recall (Anomaly): 0.9954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal (0)</th>\n",
       "      <td>167468</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.011718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anomaly (1)</th>\n",
       "      <td>5051</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.064352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std\n",
       "true_label                             \n",
       "Normal (0)   167468  0.000137  0.011718\n",
       "Anomaly (1)    5051  0.995842  0.064352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have labeled data\n",
    "result_df, mlp_model = train_and_evaluate_mlp(\n",
    "    X_train, X_eval, y_train=y_train, y_eval=y_eval,\n",
    "    hidden_layer_sizes=(128, 64), epochs=10, batch_size=32, lr=1e-3\n",
    ")\n",
    "\n",
    "print(result_df.head(10))\n",
    "metrics = evaluate_mlp_results(result_df)\n",
    "analyze_classification_results_by_label(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ff352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation metrics:\n",
      "precision : 0.9529\n",
      "recall    : 0.6575\n",
      "f1_score  : 0.7781\n",
      "auc       : 0.9989\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_mlp_results(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0284748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_evaluate_rf(X_train, X_eval, y_train, y_eval,\n",
    "                          n_estimators=100, max_depth=None, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Train a Random Forest Classifier on X_train and evaluate on X_eval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array-like or sparse matrix\n",
    "        Training feature matrix (labeled samples).\n",
    "    X_eval : array-like or sparse matrix\n",
    "        Evaluation feature matrix.\n",
    "    y_train, y_eval : array-like\n",
    "        Labels for training and evaluation sets.\n",
    "    n_estimators : int\n",
    "        Number of trees in the forest.\n",
    "    max_depth : int, optional\n",
    "        The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure.\n",
    "    contamination : float\n",
    "        Expected fraction of anomalies in the data (for anomaly detection). Not used directly with RF, \n",
    "        but can be used for thresholding when evaluating predictions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "        ['true_label', 'pred_label', 'probability']\n",
    "    model : RandomForestClassifier\n",
    "        Trained Random Forest model.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Training Random Forest on {X_train.shape[0]} samples, \"\n",
    "          f\"evaluating on {X_eval.shape[0]} samples...\")\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, verbose=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the evaluation set\n",
    "    y_pred = model.predict(X_eval)  # Predicted labels (0 for normal, 1 for anomaly)\n",
    "    probabilities = model.predict_proba(X_eval)[:, 1]  # Probability for the anomaly class (class 1)\n",
    "\n",
    "    # Build result DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        \"true_label\": y_eval,\n",
    "        \"pred_label\": y_pred,\n",
    "        \"probability\": probabilities\n",
    "    })\n",
    "\n",
    "    # Display summary\n",
    "    print(\"\\nâœ… Training complete.\")\n",
    "    print(\"Predicted label counts:\")\n",
    "    print(result_df[\"pred_label\"].value_counts())\n",
    "    print(\"Mean anomaly probability:\", np.mean(probabilities))\n",
    "\n",
    "    return result_df, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14f9e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest on 402542 samples, evaluating on 172519 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training complete.\n",
      "Predicted label counts:\n",
      "pred_label\n",
      "0    167479\n",
      "1      5040\n",
      "Name: count, dtype: int64\n",
      "Mean anomaly probability: 0.029180942515229832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    167468\n",
      "           1       1.00      1.00      1.00      5051\n",
      "\n",
      "    accuracy                           1.00    172519\n",
      "   macro avg       1.00      1.00      1.00    172519\n",
      "weighted avg       1.00      1.00      1.00    172519\n",
      "\n",
      "ROC AUC: 0.9999976811155398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "result_df, rf_model = train_and_evaluate_rf(\n",
    "    X_train=X_train,\n",
    "    X_eval=X_eval,\n",
    "    y_train=y_train,\n",
    "    y_eval=y_eval,\n",
    "    n_estimators=100,      # You can adjust the number of trees\n",
    "    max_depth=10,          # You can set the max depth of trees\n",
    "    contamination=0.05     # This can be used for thresholding, not directly in RF\n",
    ")\n",
    "\n",
    "# Optional: evaluate performance metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(result_df[\"true_label\"], result_df[\"pred_label\"]))\n",
    "\n",
    "# ROC AUC Score\n",
    "print(\"ROC AUC:\", roc_auc_score(result_df[\"true_label\"], result_df[\"probability\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andyVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
