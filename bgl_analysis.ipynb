{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccd3fe16-89c9-4b22-a97b-3944a937faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.363779 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.527847 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.675872 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.823719 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838570 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.50.982731 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838571 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.51.131467 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838571 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.51.293532 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838571 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.51.428563 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838571 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.51.601412 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "- 1117838571 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.42.51.749199 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL.log\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f17668-aeff-4e69-949f-ca8324e12718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: logparser 0.8.4\n",
      "Uninstalling logparser-0.8.4:\n",
      "  Successfully uninstalled logparser-0.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall logparser -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe3614-1ed8-46fb-8590-0e7be69c13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/logpai/logparser.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6a363f-a7e6-4082-bee4-531d0ea11059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logparser import Drain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71991df0-6f39-4fa9-9a11-af2c19110881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drain parser loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from logparser.Drain import LogParser\n",
    "print(\"Drain parser loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb91e31-806a-4ced-9a11-2c8c95b4eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc74b84-95f9-4d9b-9339-15445e13d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cb6b6a4-31ed-4769-94f9-f13d1fd984df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing done.\n",
      "   Total lines processed: 4747963\n",
      "   Normal (label=0): 4399503\n",
      "   Abnormal (label=1): 348460\n",
      "   Saved cleaned file to: C:\\Users\\Shirley\\Downloads\\BGL\\BGL_clean_for_parsing.log\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 🔧 Step 0 — Import dependencies\n",
    "# ===============================\n",
    "import re\n",
    "\n",
    "# ===============================\n",
    "# 📂 Step 1 — Input and Output paths\n",
    "# ===============================\n",
    "input_path = r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL.log\"\n",
    "output_path = r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL_clean_for_parsing.log\"\n",
    "\n",
    "# ===============================\n",
    "# 🧹 Step 2 — Preprocess logs\n",
    "# ===============================\n",
    "total = 0\n",
    "normal = 0\n",
    "abnormal = 0\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile, \\\n",
    "     open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        total += 1\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip empty\n",
    "\n",
    "        parts = line.split()\n",
    "        if len(parts) < 7:\n",
    "            continue  # skip malformed lines\n",
    "\n",
    "        # ✅ Step 2a: Label\n",
    "        first_col = parts[0]\n",
    "        if first_col == \"-\":\n",
    "            label = 0\n",
    "            normal += 1\n",
    "        else:\n",
    "            label = 1\n",
    "            abnormal += 1\n",
    "\n",
    "        # ✅ Step 2b: Timestamp\n",
    "        timestamp = parts[4]  # e.g. 2005-06-03-15.42.50.363779\n",
    "\n",
    "        # ✅ Step 2c: Message\n",
    "        # Keep everything after the 5th field as message\n",
    "        message = \" \".join(parts[5:]).strip()\n",
    "\n",
    "        # ✅ Output cleaned line\n",
    "        outfile.write(f\"{label}\\t{timestamp}\\t{message}\\n\")\n",
    "\n",
    "print(f\"✅ Preprocessing done.\")\n",
    "print(f\"   Total lines processed: {total}\")\n",
    "print(f\"   Normal (label=0): {normal}\")\n",
    "print(f\"   Abnormal (label=1): {abnormal}\")\n",
    "print(f\"   Saved cleaned file to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca81795e-41f6-4f04-b74b-3c3d5e7c3974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4747963\n",
      "Label\n",
      "0    4399503\n",
      "1     348460\n",
      "Name: count, dtype: int64\n",
      "Timestamp range: 2005-06-03-15.42.50.363779 → 2006-01-04-08.00.05.233639\n",
      "   Label                   Timestamp  \\\n",
      "0      0  2005-06-03-15.42.50.363779   \n",
      "1      0  2005-06-03-15.42.50.527847   \n",
      "2      0  2005-06-03-15.42.50.675872   \n",
      "3      0  2005-06-03-15.42.50.823719   \n",
      "4      0  2005-06-03-15.42.50.982731   \n",
      "5      0  2005-06-03-15.42.51.131467   \n",
      "6      0  2005-06-03-15.42.51.293532   \n",
      "7      0  2005-06-03-15.42.51.428563   \n",
      "8      0  2005-06-03-15.42.51.601412   \n",
      "9      0  2005-06-03-15.42.51.749199   \n",
      "\n",
      "                                             Message  \n",
      "0  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "1  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "2  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "3  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "4  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "5  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "6  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "7  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "8  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n",
      "9  R02-M1-N0-C:J12-U11 RAS KERNEL INFO instructio...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL_clean_for_parsing.log\",\n",
    "                 sep=\"\\t\", names=[\"Label\", \"Timestamp\", \"Message\"])\n",
    "\n",
    "print(\"Total rows:\", len(df))\n",
    "print(df[\"Label\"].value_counts())\n",
    "print(\"Timestamp range:\", df[\"Timestamp\"].min(), \"→\", df[\"Timestamp\"].max())\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03f20ad8-e586-4708-a0f1-337af8b7a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 4747963\n",
      "⚠️ Unexpected labels: [0 1]\n",
      "✅ All timestamps are valid\n",
      "✅ All messages are non-empty\n",
      "\n",
      "Label distribution:\n",
      "Label\n",
      "0    4399503\n",
      "1     348460\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Timestamp range:\n",
      "2005-06-03-15.42.50.363779 → 2006-01-04-08.00.05.233639\n",
      "\n",
      "Sample head:\n",
      " Label                  Timestamp                                                                      Message\n",
      "     0 2005-06-03-15.42.50.363779 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.50.527847 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.50.675872 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.50.823719 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.50.982731 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.51.131467 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.51.293532 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.51.428563 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.51.601412 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "     0 2005-06-03-15.42.51.749199 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ===============================\n",
    "# 📂 Step 0 — Input file\n",
    "# ===============================\n",
    "file_path = r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL_clean_for_parsing.log\"\n",
    "\n",
    "# ===============================\n",
    "# 🧾 Step 1 — Load preprocessed file\n",
    "# ===============================\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Timestamp\", \"Message\"])\n",
    "\n",
    "# ===============================\n",
    "# ✅ Step 2 — Basic checks\n",
    "# ===============================\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# Label check\n",
    "if set(df[\"Label\"].unique()) <= {\"0\", \"1\"}:\n",
    "    print(\"✅ Labels are valid (0/1)\")\n",
    "else:\n",
    "    print(\"⚠️ Unexpected labels:\", df[\"Label\"].unique())\n",
    "\n",
    "# Timestamp check\n",
    "def is_valid_timestamp(ts):\n",
    "    try:\n",
    "        datetime.strptime(ts, \"%Y-%m-%d-%H.%M.%S.%f\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "invalid_ts = df[~df[\"Timestamp\"].apply(is_valid_timestamp)]\n",
    "if len(invalid_ts) == 0:\n",
    "    print(\"✅ All timestamps are valid\")\n",
    "else:\n",
    "    print(f\"⚠️ {len(invalid_ts)} invalid timestamps found\")\n",
    "\n",
    "# Message check\n",
    "empty_msg = df[df[\"Message\"].str.strip() == \"\"]\n",
    "if len(empty_msg) == 0:\n",
    "    print(\"✅ All messages are non-empty\")\n",
    "else:\n",
    "    print(f\"⚠️ {len(empty_msg)} empty messages found\")\n",
    "\n",
    "# ===============================\n",
    "# 📊 Step 3 — Additional statistics\n",
    "# ===============================\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df[\"Label\"].value_counts())\n",
    "\n",
    "print(\"\\nTimestamp range:\")\n",
    "print(df[\"Timestamp\"].min(), \"→\", df[\"Timestamp\"].max())\n",
    "\n",
    "print(\"\\nSample head:\")\n",
    "print(df.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f87b60b5-d0c6-45f6-8964-9bc2ed235859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Label\n",
      "0    4295303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(output_path, sep=\"\\t\", names=[\"Label\", \"Timestamp\", \"Message\"])\n",
    "print(df[\"Label\"].unique())  # 会显示 [0] 表示全是正常\n",
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "789c7d2d-3141-457c-acd7-bba0ef875a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t2005-06-03-15.42.50.363779\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.50.527847\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.50.675872\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.50.823719\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.50.982731\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.51.131467\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.51.293532\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.51.428563\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.51.601412\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "0\t2005-06-03-15.42.51.749199\tR02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n"
     ]
    }
   ],
   "source": [
    "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "575eba80-f6fc-4a06-a6c8-f3c92e10e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading cleaned log file...\n",
      "✅ Loaded 4,747,963 log entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing logs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4747963/4747963 [16:29<00:00, 4796.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved structured logs: C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_structured.csv\n",
      "✅ Saved template summary: C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_templates.csv\n",
      "🕒 Total parsing time: 0:17:55.183756\n",
      "✅ Saved merged structured log: C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_structured_labeled.csv\n",
      "\n",
      "Top 10 templates:\n",
      " EventId                                                                                                                                                                                                                   EventTemplate  Occurrences\n",
      "82e013db                                                                                                                                                                                         <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>      1037941\n",
      "f4efd1ca                                                                                                                                     <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       656744\n",
      "73d6de92                                                                                                                                                                                 <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       585369\n",
      "023c9167                                                                                                                                                         <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       533248\n",
      "71585e7e                                                                                                                                                                         <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       532500\n",
      "76c99562                                                                                                                                                 <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       346391\n",
      "244e4fb7                                                                                                     <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       330928\n",
      "e733e90e                                                                                                                                                                                  <*> RAS KERNEL INFO CE sym <*> at <*> mask <*>       201206\n",
      "e0e27083 <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*>       146912\n",
      "8d29c08a                                                                                                                                                                    <*> RAS KERNEL INFO instruction cache parity error corrected       105924\n",
      "\n",
      "Structured log head:\n",
      " LineId                                                                      Content                                                EventTemplate  EventId  Label                  Timestamp\n",
      "      1 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.50.363779\n",
      "      2 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.50.527847\n",
      "      3 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.50.675872\n",
      "      4 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.50.823719\n",
      "      5 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.50.982731\n",
      "      6 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.51.131467\n",
      "      7 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.51.293532\n",
      "      8 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.51.428563\n",
      "      9 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.51.601412\n",
      "     10 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected <*> RAS KERNEL INFO instruction cache parity error corrected 8d29c08a      0 2005-06-03-15.42.51.749199\n",
      "\n",
      "Total structured rows: 4,747,963\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 🔧 Step 0 — Import dependencies\n",
    "# ===============================\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# ===============================\n",
    "# 🧠 Step 1 — Define SimpleDrain Parser\n",
    "# ===============================\n",
    "class SimpleDrain:\n",
    "    def __init__(self, st=0.5, max_templates=None, verbose=True):\n",
    "        \"\"\"\n",
    "        st: similarity threshold (0~1), larger = stricter merging\n",
    "        max_templates: optional limit on number of templates\n",
    "        \"\"\"\n",
    "        self.st = st\n",
    "        self.max_templates = max_templates\n",
    "        self.templates = []\n",
    "        self.template_counts = []\n",
    "        self.log_to_template = []\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def tokenize(self, line):\n",
    "        \"\"\"Split message into tokens\"\"\"\n",
    "        return re.split(r\"\\s+\", line.strip())\n",
    "\n",
    "    def similarity(self, seq1, seq2):\n",
    "        \"\"\"Compute token-level similarity\"\"\"\n",
    "        if not seq1 or not seq2:\n",
    "            return 0.0\n",
    "        same = sum(1 for i in range(min(len(seq1), len(seq2)))\n",
    "                   if seq1[i] == seq2[i] or seq1[i] == \"<*>\" or seq2[i] == \"<*>\")\n",
    "        return same / max(len(seq1), len(seq2))\n",
    "\n",
    "    def merge_template(self, temp, tokens):\n",
    "        \"\"\"Merge two templates\"\"\"\n",
    "        L = max(len(temp), len(tokens))\n",
    "        merged = []\n",
    "        for i in range(L):\n",
    "            t = temp[i] if i < len(temp) else \"<*>\"\n",
    "            s = tokens[i] if i < len(tokens) else \"<*>\"\n",
    "            merged.append(t if t == s else \"<*>\")\n",
    "        return merged\n",
    "\n",
    "    def add_log(self, tokens):\n",
    "        \"\"\"Add new log to template pool\"\"\"\n",
    "        best_sim, best_idx = -1.0, None\n",
    "        for idx, temp in enumerate(self.templates):\n",
    "            sim = self.similarity(temp, tokens)\n",
    "            if sim > best_sim:\n",
    "                best_sim, best_idx = sim, idx\n",
    "\n",
    "        if best_sim >= self.st and best_idx is not None:\n",
    "            new_temp = self.merge_template(self.templates[best_idx], tokens)\n",
    "            self.templates[best_idx] = new_temp\n",
    "            self.template_counts[best_idx] += 1\n",
    "            return best_idx\n",
    "        else:\n",
    "            if self.max_templates and len(self.templates) >= self.max_templates:\n",
    "                self.template_counts[best_idx] += 1\n",
    "                new_temp = self.merge_template(self.templates[best_idx], tokens)\n",
    "                self.templates[best_idx] = new_temp\n",
    "                return best_idx\n",
    "            else:\n",
    "                self.templates.append(tokens)\n",
    "                self.template_counts.append(1)\n",
    "                return len(self.templates) - 1\n",
    "\n",
    "    def parse_lines(self, lines):\n",
    "        \"\"\"Main parsing\"\"\"\n",
    "        self.log_to_template = []\n",
    "        iterator = tqdm(lines, desc=\"Parsing logs\") if self.verbose else lines\n",
    "        for line in iterator:\n",
    "            tokens = self.tokenize(line)\n",
    "            idx = self.add_log(tokens)\n",
    "            self.log_to_template.append(idx)\n",
    "\n",
    "    def save_results(self, lines, output_dir, base_name=\"BGL\"):\n",
    "        \"\"\"Save structured results\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        records = []\n",
    "        for i, line in enumerate(lines):\n",
    "            tidx = self.log_to_template[i]\n",
    "            template_tokens = self.templates[tidx]\n",
    "            template_str = \" \".join(template_tokens)\n",
    "            event_id = hashlib.md5(template_str.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            records.append({\n",
    "                \"LineId\": i + 1,\n",
    "                \"Content\": line,\n",
    "                \"EventTemplate\": template_str,\n",
    "                \"EventId\": event_id\n",
    "            })\n",
    "        df_struct = pd.DataFrame(records)\n",
    "        struct_path = os.path.join(output_dir, f\"{base_name}_structured.csv\")\n",
    "        df_struct.to_csv(struct_path, index=False, encoding=\"utf-8\")\n",
    "        if self.verbose:\n",
    "            print(f\"✅ Saved structured logs: {struct_path}\")\n",
    "\n",
    "        # Template summary\n",
    "        temps = []\n",
    "        for i, temp in enumerate(self.templates):\n",
    "            temp_str = \" \".join(temp)\n",
    "            event_id = hashlib.md5(temp_str.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            occ = self.template_counts[i]\n",
    "            temps.append({\"EventId\": event_id, \"EventTemplate\": temp_str, \"Occurrences\": occ})\n",
    "        df_temp = pd.DataFrame(temps).sort_values(by=\"Occurrences\", ascending=False)\n",
    "        temp_path = os.path.join(output_dir, f\"{base_name}_templates.csv\")\n",
    "        df_temp.to_csv(temp_path, index=False, encoding=\"utf-8\")\n",
    "        if self.verbose:\n",
    "            print(f\"✅ Saved template summary: {temp_path}\")\n",
    "\n",
    "# ===============================\n",
    "# 📂 Step 2 — Paths\n",
    "# ===============================\n",
    "input_file = r\"C:\\Users\\Shirley\\Downloads\\BGL\\BGL_clean_for_parsing.log\"\n",
    "output_dir = r\"C:\\Users\\Shirley\\Downloads\\BGL\\result_new\"\n",
    "base_name = \"BGL\"\n",
    "\n",
    "# ===============================\n",
    "# 🔍 Step 3 — Load cleaned data\n",
    "# ===============================\n",
    "print(\"🔍 Loading cleaned log file...\")\n",
    "data = pd.read_csv(input_file, sep=\"\\t\", header=None, names=[\"Label\", \"Timestamp\", \"Message\"], dtype=str)\n",
    "print(f\"✅ Loaded {len(data):,} log entries\")\n",
    "\n",
    "logs = data[\"Message\"].tolist()\n",
    "\n",
    "# ===============================\n",
    "# ⚙️ Step 4 — Run SimpleDrain\n",
    "# ===============================\n",
    "parser = SimpleDrain(st=0.5, max_templates=None, verbose=True)\n",
    "start_time = datetime.now()\n",
    "parser.parse_lines(logs)\n",
    "parser.save_results(logs, output_dir, base_name=base_name)\n",
    "print(f\"🕒 Total parsing time: {datetime.now() - start_time}\")\n",
    "\n",
    "# ===============================\n",
    "# 🧾 Step 5 — Merge label + timestamp\n",
    "# ===============================\n",
    "structured_path = os.path.join(output_dir, f\"{base_name}_structured.csv\")\n",
    "structured = pd.read_csv(structured_path)\n",
    "structured[\"Label\"] = data[\"Label\"].astype(int).values\n",
    "structured[\"Timestamp\"] = data[\"Timestamp\"].values\n",
    "\n",
    "merged_path = os.path.join(output_dir, f\"{base_name}_structured_labeled.csv\")\n",
    "structured.to_csv(merged_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Saved merged structured log: {merged_path}\")\n",
    "\n",
    "# ===============================\n",
    "# 🔎 Step 6 — Quick sanity check\n",
    "# ===============================\n",
    "df_temp = pd.read_csv(os.path.join(output_dir, f\"{base_name}_templates.csv\"))\n",
    "print(\"\\nTop 10 templates:\")\n",
    "print(df_temp.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nStructured log head:\")\n",
    "print(structured.head(10).to_string(index=False))\n",
    "print(f\"\\nTotal structured rows: {len(structured):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f96223d3-dec5-4a06-a574-9e9c39efd67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    4399503\n",
      "1     348460\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_structured_labeled.csv\")\n",
    "print(df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "794ee89f-33b1-4a56-91ce-25c15258b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading structured log file...\n",
      "✅ Loaded 4,747,963 structured log entries\n",
      "🔧 Generating TF-IDF sparse matrix (max_features=5000)...\n",
      "✅ TF-IDF sparse matrix saved to: C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_tfidf_matrix.npz\n",
      "✅ Metadata (labels + timestamps) saved to: C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_metadata.csv\n",
      "\n",
      "🧩 Sanity check results:\n",
      "TF-IDF shape: (4747963, 144)\n",
      "Non-zero entries: 4,195,276 (0.6136% density)\n",
      "Label distribution:\n",
      "Label\n",
      "0    4399503\n",
      "1     348460\n",
      "Name: count, dtype: int64\n",
      "Timestamp range: 2005-06-03-15.42.50.363779 → 2006-01-04-08.00.05.233639\n",
      "✅ Row count matches between TF-IDF matrix and metadata.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 🚀 Step 0 — Import dependencies\n",
    "# ============================================\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# 📂 Step 1 — Input / Output paths\n",
    "# ============================================\n",
    "structured_path = r\"C:\\Users\\Shirley\\Downloads\\BGL\\result_new\\BGL_structured_labeled.csv\"\n",
    "output_dir = r\"C:\\Users\\Shirley\\Downloads\\BGL\\result_new\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "tfidf_npz_path = os.path.join(output_dir, \"BGL_tfidf_matrix.npz\")\n",
    "meta_csv_path = os.path.join(output_dir, \"BGL_metadata.csv\")\n",
    "\n",
    "print(\"🔍 Loading structured log file...\")\n",
    "df = pd.read_csv(structured_path)\n",
    "print(f\"✅ Loaded {len(df):,} structured log entries\")\n",
    "\n",
    "# ============================================\n",
    "# 🧠 Step 2 — Select text field for TF-IDF\n",
    "# ============================================\n",
    "# 如果 replication 需要按模板分析，使用 EventTemplate；\n",
    "# 如果按原始日志分析，改为 df[\"Content\"]\n",
    "if \"EventTemplate\" in df.columns:\n",
    "    texts = df[\"EventTemplate\"].astype(str).values\n",
    "else:\n",
    "    texts = df[\"Content\"].astype(str).values\n",
    "\n",
    "# ============================================\n",
    "# ⚙️ Step 3 — TF-IDF vectorization\n",
    "# ============================================\n",
    "print(\"🔧 Generating TF-IDF sparse matrix (max_features=5000)...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ============================================\n",
    "# 💾 Step 4 — Save sparse TF-IDF matrix + metadata\n",
    "# ============================================\n",
    "sparse.save_npz(tfidf_npz_path, tfidf_matrix)\n",
    "meta_df = df[[\"Label\", \"Timestamp\"]].copy()\n",
    "meta_df.to_csv(meta_csv_path, index=False)\n",
    "\n",
    "print(f\"✅ TF-IDF sparse matrix saved to: {tfidf_npz_path}\")\n",
    "print(f\"✅ Metadata (labels + timestamps) saved to: {meta_csv_path}\")\n",
    "\n",
    "# ============================================\n",
    "# 🔎 Step 5 — Quick sanity check\n",
    "# ============================================\n",
    "print(\"\\n🧩 Sanity check results:\")\n",
    "print(f\"TF-IDF shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {tfidf_matrix.nnz:,} \"\n",
    "      f\"({tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]):.4%} density)\")\n",
    "print(f\"Label distribution:\\n{meta_df['Label'].value_counts()}\")\n",
    "print(f\"Timestamp range: {meta_df['Timestamp'].iloc[0]} → {meta_df['Timestamp'].iloc[-1]}\")\n",
    "\n",
    "# Verify alignment\n",
    "if len(meta_df) == tfidf_matrix.shape[0]:\n",
    "    print(\"✅ Row count matches between TF-IDF matrix and metadata.\")\n",
    "else:\n",
    "    print(\"❌ Row count mismatch — check preprocessing or parsing outputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9228de6-a48b-4071-863a-a869019a991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in BGL folder:\n",
      "- anaconda_projects\n",
      "- BGL.log\n",
      "- BGL_clean.log\n",
      "- BGL_clean_for_parsing.log\n",
      "- result_custom\n",
      "- result_full\n",
      "- result_new\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "bgl_dir = r\"C:\\Users\\Shirley\\Downloads\\BGL\"\n",
    "\n",
    "print(\"Files in BGL folder:\")\n",
    "for f in os.listdir(bgl_dir):\n",
    "    print(\"-\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4341809f-c48f-443f-97c5-b28a615c7808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\System32\\bgl_analysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "notebook_path = os.path.abspath(\"bgl_analysis.ipynb\")\n",
    "print(notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384802da-4f61-4a75-958d-33f62e59c058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Windows\\\\System32'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd61808-76a8-426e-82ed-3c6bc5035a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-logparser]",
   "language": "python",
   "name": "conda-env-.conda-logparser-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
